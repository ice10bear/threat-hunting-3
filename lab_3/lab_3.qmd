---
title: "Практическое задание №3"
author: "Емельяненко Мария БИСО-01-20"
format:   
  md:
    output-file: README.md
---

# Анализ данных сетевого трафика при помощи библиотеки `Arrow`

## Цель работы

1.  Изучить возможности технологии **Apache Arrow** для обработки и анализа больших данных
2.  Получить навыки применения Arrow совместно с языком программирования R
3.  Получить навыки анализа метаинфомации о сетевом трафике
4.  Получить навыки применения облачных технологий хранения, подготовки и анализа данных: **Yandex Object Storage**, **Rstudio Server**

## Исходные данные

1.  ОС Windows 10
2.  RStudio Server
3.  Yandex Cloud: S3 Object Storage
4.  Датасет tm_data.pqt

**Общая ситуация**

Вы -- специалист по информационной безопасности компании "СуперМегатек". Вы, являясь специалистом Threat Hunting, часто используете информацию о сетевом трафике для обнаружения подозрительной и вредоносной активности. Помогите защитить Вашу компанию от международной хакерской группировки AnonMasons.

У Вас есть данные сетевой активности в корпоративной сети компании "СуперМегатек". Данные хранятся в Yandex Object Storage.

## Задание

Используя язык программирования R, библиотеку `arrow` и облачную IDE Rstudio Server, развернутую в **Yandex Cloud**, выполнить задания и составить отчет

## Ход работы

### Шаг 1. Настройка подключения к IDE Rstudio Server

##### 1. Подключимся к удалённому серверу через `ssh` и сразу поменяем пароль от пользователя `user21`:

##### ![](images/image-1187500351.png)

##### ![](images/image-1015482743.png)

##### 2. Перейдём по адресу `locahost:8787` и залогинимся под нашим пользователем:

##### ![](images/image-1219109733.png)

![](images/image-1101470570.png)

##### 3. Создадим пару ssh ключей и склонируем репозиторий с GitHub:

##### ![](images/image-1257755783.png)4. Добавим публичный ключ в список знакомых на GitHub, для того чтобы потом можно было сделать push:

### ![](images/image-505595434.png)

### ![](images/image-1733669990.png)Шаг 2. Установка библиотек и импорт датасета

Установим необходимые билбиотеки:

```{r}
library(arrow, warn.conflicts = FALSE)
library(tidyverse, warn.conflicts = FALSE)
```

Скачаем датасет:

```{r}
dir.create("data", showWarnings = FALSE)

curl::multi_download(
  "https://storage.yandexcloud.net/arrow-datasets/tm_data.pqt",
  "data/tm_data.pqt",
  resume = TRUE
)
```

Откроем датасет и взглянем на него:

```{r}
df <- arrow::open_dataset(sources = "data/tm_data.pqt", 
                          format  = "parquet")

df %>% glimpse()
```

Преобразуем тип данных для поля `timestamp`:

```{r}
df <- df %>%
  mutate(timestamp = as_datetime(timestamp / 1000, origin = "1970-01-01", tz = "UTC"))

df %>% glimpse()
```

### Шаг 3. Выполнение заданий

##### Задание 1: Надите утечку данных из Вашей сети

Важнейшие документы с результатами нашей исследовательской деятельности в области создания вакцин скачиваются в виде больших заархивированных дампов. Один из хостов в нашей сети используется для пересылки этой информации -- он пересылает гораздо больше информации на внешние ресурсы в Интернете, чем остальные компьютеры нашей сети. Определите его IP-адрес.

```{r}
df_filtered <- df %>%
  filter(str_detect(src, "^1[2-4].")) %>%
  filter(!str_detect(dst, "^1[2-4]."))

answer_1 <- df_filtered %>%
  group_by(src) %>% 
  summarise(sum_traffic = sum(bytes)) %>%
  arrange(desc(sum_traffic)) %>%
  head(1)

answer_1 %>% collect()
```

**Ответ: 13.37.84.125**

##### Задание 2: Надите утечку данных 2

Другой атакующий установил автоматическую задачу в системном планировщике `cron` для экспорта содержимого внутренней wiki системы. Эта система генерирует большое количество трафика в нерабочие часы, больше чем остальные хосты. Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителя из предыдущей задачи.

Для начала необходимо определить рабочие часы: в нашем случае это время с 16:00 до 23:59, если судить по движению трафика

```{r}
work_time <- df %>%
  group_by(hour(timestamp)) %>%
  summarise(sum_traffic = sum(bytes)) %>%
  arrange(desc(sum_traffic))

work_time %>% collect()
```

Теперь найдём IP-адрес нарушителя по максимальному объёму исходящего трафика в нерабочее время:

```{r}
answer_2 <- df_filtered %>%
  filter(!str_detect(src, "^13.37.84.125$")) %>%
  filter(!between(hour(timestamp), 16, 23)) %>%
  group_by(src) %>%
  summarise(sum_traffic = sum(bytes)) %>%
  arrange(desc(sum_traffic)) %>%
  head(1)
  
answer_2 %>% collect()
```

**Ответ: 12.55.77.96**

##### Задание 3: Надите утечку данных 3

Еще один нарушитель собирает содержимое электронной почты и отправляет в Интернет используя порт, который обычно используется для другого типа трафика. Атакующий пересылает большое количество информации используя этот порт, которое нехарактерно для других хостов, использующих этот номер порта. Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителей из предыдущих задач.

Для начала найдём средние значения трафика для каждого порта:

```{r}
avg_traffic_by_port <- df_filtered %>%
  group_by(src, port) %>%
  summarise(bytes_ip_port = sum(bytes)) %>%
  group_by(port) %>%
  summarise(avg_traffic = mean(bytes_ip_port)) %>%
  arrange(desc(avg_traffic))

avg_traffic_by_port %>% collect() %>% head(5)
```

Также, найдём максимальные значения трафика по порту:

```{r}
max_src_traffic_by_port <- df_filtered %>%
  group_by(src, port) %>%
  summarise(sum_traffic = sum(bytes)) %>%
  collect() %>%
  group_by(port) %>%
  top_n(1, wt = sum_traffic) %>%
  arrange(desc(sum_traffic))

max_src_traffic_by_port %>% collect() %>% head(5)
```

Соединим 2 предыдущих датафрейма по полю `port`:

```{r}
merged_df <- merge(max_src_traffic_by_port, avg_traffic_by_port, by = "port")

merged_df %>% collect() %>% head(5)
```

Найдём ip-адрес нарушителя, чьё отношение максимального трафика по порту к среднему трафику по порту:

```{r}
answer_3 <- merged_df %>%
  mutate(anomally_attitide = sum_traffic / avg_traffic) %>%
  arrange(desc(anomally_attitide)) %>%
  head(1)

answer_3 %>% collect()
```

**Ответ: 12.30.96.87**

## Оценка результатов

В результате практической работы был проведен анализ сетевой активности с помощью `Apache Arrow` и были найдены утечки данных

## Вывод

Были получены навыки работы с технологией `Apache Arrow` для обработки и анализа больших данных
